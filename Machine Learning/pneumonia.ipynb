{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dims = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (img_dims, img_dims, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "input_path = '/Users/maulikdave/Documents/Machine Learning/chest_xray/'\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory(directory=input_path+'train',\n",
    "target_size = (img_dims, img_dims),\n",
    "batch_size = batch_size,\n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory(directory=input_path+'test',\n",
    "target_size = (img_dims, img_dims),\n",
    "batch_size = batch_size,\n",
    "class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/lxc2kmqn22ng6_3m7gxwv0m80000gn/T/ipykernel_5188/3841266858.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = classifier.fit_generator(            training_set, steps_per_epoch=training_set.samples // batch_size,             epochs=epochs, validation_data=test_set,             validation_steps= test_set.samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.8206WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "163/163 [==============================] - 32s 193ms/step - loss: 0.5001 - accuracy: 0.8206 - val_loss: 0.4209 - val_accuracy: 0.7949\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 29s 176ms/step - loss: 0.2270 - accuracy: 0.9114\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 29s 179ms/step - loss: 0.2103 - accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 29s 176ms/step - loss: 0.1958 - accuracy: 0.9245\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 29s 177ms/step - loss: 0.1818 - accuracy: 0.9273\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 29s 177ms/step - loss: 0.1832 - accuracy: 0.9298\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 29s 176ms/step - loss: 0.1511 - accuracy: 0.9387\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 28s 171ms/step - loss: 0.1628 - accuracy: 0.9350\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 27s 165ms/step - loss: 0.1587 - accuracy: 0.9377\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 27s 164ms/step - loss: 0.1450 - accuracy: 0.9425\n"
     ]
    }
   ],
   "source": [
    "epochs = 10  \n",
    "hist = classifier.fit_generator(            training_set, steps_per_epoch=training_set.samples // batch_size,             epochs=epochs, validation_data=test_set,             validation_steps= test_set.samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
